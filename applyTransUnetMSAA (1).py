
import os
import random
import numpy as np
import torch
import torch.optim as optim
from torch import nn
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from transformers.commands import train
from tensorflow.keras.optimizers import Adam
# from unet.unet3 import UNet3D
import torch.nn.functional as F
from utils import DataGenerator
import configs as configs
from TransUnetMSAA import VisionTransformer
from utils import DataGenerator
import time
from tqdm import tqdm
from sklearn.metrics import precision_recall_fscore_support, accuracy_score
from sklearn.metrics import confusion_matrix
import os
import matplotlib.pyplot as plt
import seaborn as sns
from torch.optim import Adam

def calculate_metrics(preds, labels, num_classes=3):
    preds = preds.flatten()
    labels = labels.flatten()
    iou_list, precision_list, recall_list, dice_list, f1_list = [], [], [], [], []
    for cls in range(num_classes):
        pred_cls = (preds == cls)
        label_cls = (labels == cls)

        TP = np.logical_and(pred_cls, label_cls).sum()
        FP = np.logical_and(pred_cls, ~label_cls).sum()
        FN = np.logical_and(~pred_cls, label_cls).sum()

        union = np.logical_or(pred_cls, label_cls).sum()
        iou = TP / (union + 1e-6)
        precision = TP / (TP + FP + 1e-6)
        recall = TP / (TP + FN + 1e-6)
        dice = 2 * TP / (2 * TP + FP + FN + 1e-6)
        f1 = 2 * precision * recall / (precision + recall + 1e-6)

        iou_list.append(iou)
        precision_list.append(precision)
        recall_list.append(recall)
        dice_list.append(dice)
        f1_list.append(f1)

    return iou_list, precision_list, recall_list, dice_list, f1_list

def calculate_macro_average(iou, precision, recall, dice, f1):
    return (
        np.mean(iou),
        np.mean(precision),
        np.mean(recall),
        np.mean(dice),
        np.mean(f1)
    )

def plot_confusion_matrix(y_true, y_pred, class_names, epoch, save_path):
    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))  # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)  # æ¯è¡Œå½’ä¸€åŒ–ä¸ºæ¯”ä¾‹

    # é¿å…é™¤ä»¥0å¯¼è‡´çš„ NaN
    cm_normalized = np.nan_to_num(cm_normalized)

    plt.figure(figsize=(8, 6))
    sns.heatmap(
        cm_normalized,
        annot=True,
        fmt=".2%",  # æ˜¾ç¤ºä¸ºç™¾åˆ†æ¯”
        cmap="Blues",
        xticklabels=class_names,
        yticklabels=class_names,
        cbar=True
    )
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.title(f'Confusion Matrix (Normalized %) - Epoch {epoch}')
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()
    
# ä¸‰çº¿æ€§æ’å€¼å¹³æ»‘æƒé‡å‡½æ•°ä¿æŒä¸å˜
def create_trilinear_weights(size, overlap):
    weights = np.ones((size, size, size), dtype=np.float32)
    for i in range(size):
        for j in range(size):
            for k in range(size):
                wi = 1.0
                wj = 1.0
                wk = 1.0
                if i < overlap:
                    wi = (i + 1) / (overlap + 1)
                elif i >= size - overlap:
                    wi = (size - i) / (overlap + 1)
                if j < overlap:
                    wj = (j + 1) / (overlap + 1)
                elif j >= size - overlap:
                    wj = (size - j) / (overlap + 1)
                if k < overlap:
                    wk = (k + 1) / (overlap + 1)
                elif k >= size - overlap:
                    wk = (size - k) / (overlap + 1)
                weights[i, j, k] = wi * wj * wk
    return torch.from_numpy(weights)

def get_start_indices(length, window, overlap):
    """è¿”å›èµ·ç‚¹åˆ—è¡¨ï¼Œæ­¥é•¿ = window - overlapï¼›å¹¶ä¿è¯æœ€åä¸€ä¸ªå—è¦†ç›–åˆ°æœ«å°¾ã€‚"""
    stride = max(1, window - overlap)
    idxs = list(range(0, max(0, length - window + 1), stride))
    if len(idxs) == 0 or idxs[-1] != length - window:
        idxs.append(length - window)
    return idxs

def goFakeValidation(model, fname, output_dir):
    # å®šä¹‰è·¯å¾„
    seisPath = "/root/autodl-fs/ChannelKarst/seismic/"
    lxpath = "/root/autodl-fs/ChannelKarst/label/"
    predPath = "/root/autodl-fs/ChannelKarst/px/"
    
    # åŸå§‹æ•°æ®ä½“ç´ ç»´åº¦ (D, H, W)
    n1, n2, n3 = 256, 256, 256
    input_shape = (n1, n2, n3)  # ä¿®æ”¹ä¸º256x256x256
    
    # 3D patch é…ç½®
    patch_d = patch_h = patch_w = 128
    overlap = 2  # æ¯ä¸ªç»´åº¦çš„é‡å ä½“ç´ æ•°
    
    try:
        gx = loadData(n1, n2, n3, seisPath, fname + '.dat')
        gx = np.reshape(gx, (1, 1, n1, n2, n3))  # ä¿®æ”¹ä¸ºPyTorchæ ¼å¼

        print("âœ… Data loaded. Shape:", gx.shape)  # [1,1,D,H,W]
        
        # # åŠ è½½æ ‡ç­¾æ•°æ®
        # label
        lx = loadData1(n1, n2, n3, lxpath, fname + '.dat')
        ls = np.reshape(lx, (1, 1, n1, n2, n3))
        print("ğŸ“Š ls unique:", np.unique(ls, return_counts=True))
        
        # æ˜ å°„æ ‡ç­¾å€¼åˆ°0,1,2
        # æ ¹æ®æ ‡ç­¾å€¼çš„åˆ†å¸ƒï¼Œå°†æœ€å°å€¼æ˜ å°„ä¸º0ï¼Œä¸­é—´å€¼æ˜ å°„ä¸º1ï¼Œæœ€å¤§å€¼æ˜ å°„ä¸º2
        unique_vals = np.unique(lx)
        sorted_vals = np.sort(unique_vals)
        
        label_mapping = {
            sorted_vals[0]: 0,  # æœ€å°å€¼æ˜ å°„ä¸º0ï¼ˆèƒŒæ™¯ï¼‰
            sorted_vals[1]: 1,  # ä¸­é—´å€¼æ˜ å°„ä¸º1ï¼ˆæ²³é“ï¼‰
            sorted_vals[2]: 2   # æœ€å¤§å€¼æ˜ å°„ä¸º2ï¼ˆæº¶æ´ï¼‰
        }
        
        labels_mapped = np.copy(lx)
        for src_val, dst_val in label_mapping.items():
            labels_mapped[lx == src_val] = dst_val
        print("ğŸ“Š Mapped labels unique:", np.unique(labels_mapped, return_counts=True))
        
    except Exception as e:
        print(f"âŒ Error loading data: {e}")
        return
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device).eval()
    gx = torch.from_numpy(gx).to(device)  # [1,1,D,H,W]
    
    # è¾“å‡ºå¼ é‡ä¸æƒé‡å›¾ï¼ˆæŒ‰ç±»åˆ«æ•° 3ï¼‰
    B, C, D, H, W = gx.shape
    num_classes = 3
    output = torch.zeros((B, num_classes, D, H, W), device=device)
    weight_map = torch.zeros((B, 1, D, H, W), device=device)
    
    # é¢„è®¡ç®—å¹³æ»‘æƒé‡ (ä¸‰çº¿æ€§æ ¸)ï¼Œå¹¿æ’­åˆ° [B,1,d,h,w]
    weight = create_trilinear_weights(patch_d, overlap).to(device)  # [128,128,128]
    weight = weight.unsqueeze(0).unsqueeze(0)  # [1,1,128,128,128]
    
    # è®¡ç®—ä¸‰ä¸ªç»´åº¦çš„èµ·ç‚¹ç´¢å¼•
    d_starts = get_start_indices(D, patch_d, overlap)
    h_starts = get_start_indices(H, patch_h, overlap)
    w_starts = get_start_indices(W, patch_w, overlap)
    
    start = time.time()
    print("ğŸš€ Running 3D sliding-window prediction with trilinear smoothing...")
    print(f" D starts: {d_starts}")
    print(f" H starts: {h_starts}")
    print(f" W starts: {w_starts}")
    
    try:
        with torch.no_grad():
            for ds in d_starts:
                de = ds + patch_d
                for hs in h_starts:
                    he = hs + patch_h
                    for ws in w_starts:
                        we = ws + patch_w
                        # å– 3D patch: [B, C, 128,128,128]
                        patch = gx[:, :, ds:de, hs:he, ws:we]
                        
                        # æ¨¡å‹å‰å‘: æœŸæœ›è¾“å‡º [B, num_classes, 128,128,128]
                        pred_patch = model(patch)
                        
                        # ä¸‰çº¿æ€§æƒé‡å¹³æ»‘
                        pred_patch = pred_patch * weight
                        
                        # ç´¯åŠ é¢„æµ‹ä¸æƒé‡
                        output[:, :, ds:de, hs:he, ws:we] += pred_patch
                        weight_map[:, :, ds:de, hs:he, ws:we] += weight
            
            # é¿å…é™¤é›¶ï¼ˆé€šå¸¸ä¸ä¼šä¸ºé›¶ï¼‰
            weight_map = torch.clamp(weight_map, min=1e-6)
            output /= weight_map  # å¹¿æ’­åˆ°ç±»åˆ«ç»´
            
            # å–ç±»åˆ«æ ‡ç­¾
            preds = torch.argmax(output, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)
            
            print("âœ… Prediction completed in {:.2f}s.".format(time.time() - start))
            print("Prediction shape:", preds.shape)  # (D,H,W)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(predPath, exist_ok=True)
            
            # ä¿å­˜é¢„æµ‹ç»“æœ
            preds.astype(np.float32).tofile(os.path.join(predPath, f"91{fname}_pred.dat"))
            (preds == 1).astype(np.float32).tofile(os.path.join(predPath, f"91{fname}_river.dat"))
            (preds == 2).astype(np.float32).tofile(os.path.join(predPath, f"91{fname}_cave.dat"))
            
            print("âœ… Saved river and cave masks.")

            # ===== è®¡ç®—å®å¹³å‡æŒ‡æ ‡ =====
            # ä½¿ç”¨æ˜ å°„åçš„æ ‡ç­¾æ•°æ®
            labels = labels_mapped
            
            # å±•å¹³é¢„æµ‹å’Œæ ‡ç­¾
            preds_flat = preds.flatten()
            labels_flat = labels.flatten()
            
            # 3. è®¡ç®—æŒ‡æ ‡
            iou_per_class, precision_per_class, recall_per_class, dice_per_class, f1_per_class = calculate_metrics(
                preds_flat, labels_flat, num_classes=3
            )
            
            # 4. è®¡ç®—å®å¹³å‡
            macro_iou = np.mean(iou_per_class)
            macro_precision = np.mean(precision_per_class)
            macro_recall = np.mean(recall_per_class)
            macro_dice = np.mean(dice_per_class)
            macro_f1 = np.mean(f1_per_class)
            
            # 5. æ‰“å°ç»“æœ
            print(f"ğŸŒ å®å¹³å‡: IoU={macro_iou:.4f}, Precision={macro_precision:.4f}, Recall={macro_recall:.4f}, F1={macro_f1:.4f}, Dice={macro_dice:.4f}")
            print("ğŸ“Š preds unique:", np.unique(preds, return_counts=True))
            print("ğŸ“Š labels unique:", np.unique(labels, return_counts=True))
            
            # 6. æŒ‰ç±»åˆ«è¾“å‡ºç»“æœ
            class_names = ['èƒŒæ™¯', 'æ²³é“', 'æº¶æ´']
            print(f"{fname}_175")
            for i, cls_name in enumerate(class_names):
                print(
                    f"[{cls_name}(ç±»åˆ«{i})] ç²¾åº¦: {precision_per_class[i]:.4f}, å¬å›ç‡: {recall_per_class[i]:.4f}, "
                    f"F1: {f1_per_class[i]:.4f}, IoU: {iou_per_class[i]:.4f}, Dice: {dice_per_class[i]:.4f}"
                )
            
            # 7. ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶
            metrics_log_path = os.path.join(predPath, "91metrics_log.txt")
            with open(metrics_log_path, "a") as file:
                file.write(f"===== æ ·æœ¬ {fname} è¯„ä¼°ç»“æœ =====\n")
                file.write(f"å®å¹³å‡: IoU={macro_iou:.4f}, Precision={macro_precision:.4f}, Recall={macro_recall:.4f}, F1={macro_f1:.4f}, Dice={macro_dice:.4f}\n")
                for i, cls_name in enumerate(class_names):
                    file.write(
                        f"[{cls_name}(ç±»åˆ«{i})] ç²¾åº¦: {precision_per_class[i]:.4f}, å¬å›ç‡: {recall_per_class[i]:.4f}, "
                        f"F1: {f1_per_class[i]:.4f}, IoU: {iou_per_class[i]:.4f}, Dice: {dice_per_class[i]:.4f}\n"
                    )
                file.write("\n")
            
            # 8. ç»˜åˆ¶æ··æ·†çŸ©é˜µ
            plot_confusion_matrix(
                y_true=labels_flat,
                y_pred=preds_flat,
                class_names=class_names,
                epoch=fname,  # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºepochæ ‡è¯†
                save_path=os.path.join(predPath, f"{fname}_TUMSAAconfusion.png")
            )
            print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜: {fname}_TUMSAAconfusion.png")
            
    except Exception as e:
        print(f"âŒ Error during prediction: {e}")


        
def loadData(n1, n2, n3, path, fname):
    gx = np.fromfile(path + fname, dtype=np.single)
    gm, gs = np.mean(gx), np.std(gx)
    gx = (gx - gm) / gs
    gx = np.reshape(gx, (n3, n2, n1))
    gx = np.transpose(gx)
    return gx

def loadData1(n1, n2, n3, path, fname):
    lx = np.fromfile(path + fname, dtype=np.int8)
    lm, ls = np.mean(lx), np.std(lx)
    lx = lx - lm
    lx = lx / ls
    lx = np.reshape(lx, (n3, n2, n1))
    lx = np.transpose(lx)
    return lx

import os
import time
import numpy as np
import torch
import torch.nn.functional as F

# ä¸‰çº¿æ€§æ’å€¼å¹³æ»‘æƒé‡
def create_trilinear_weights(size, overlap):
    weights = np.ones((size, size, size), dtype=np.float32)
    for i in range(size):
        for j in range(size):
            for k in range(size):
                wi = 1.0
                wj = 1.0
                wk = 1.0
                if i < overlap:
                    wi = (i + 1) / (overlap + 1)
                elif i >= size - overlap:
                    wi = (size - i) / (overlap + 1)
                if j < overlap:
                    wj = (j + 1) / (overlap + 1)
                elif j >= size - overlap:
                    wj = (size - j) / (overlap + 1)
                if k < overlap:
                    wk = (k + 1) / (overlap + 1)
                elif k >= size - overlap:
                    wk = (size - k) / (overlap + 1)
                weights[i, j, k] = wi * wj * wk
    return torch.from_numpy(weights)

import os, time
import numpy as np
import torch

def get_start_indices(length, window, overlap):
    """è¿”å›èµ·ç‚¹åˆ—è¡¨ï¼Œæ­¥é•¿ = window - overlapï¼›å¹¶ä¿è¯æœ€åä¸€ä¸ªå—è¦†ç›–åˆ°æœ«å°¾ã€‚"""
    stride = max(1, window - overlap)
    idxs = list(range(0, max(0, length - window + 1), stride))
    if len(idxs) == 0 or idxs[-1] != length - window:
        idxs.append(length - window)
    return idxs

def goJie(model, fname, output_dir):
    fpath = "/root/autodl-fs/"
    # åŸå§‹æ•°æ®ä½“ç´ ç»´åº¦ (D, H, W)
    input_shape = (128, 896, 384)
    # input_shape = (128, 512, 640)
    # input_shape = (128, 256, 256)
    # input_shape = (128, 512, 512)

    # 3D patch é…ç½®
    patch_d = patch_h = patch_w = 128
    overlap = 2  # æ¯ä¸ªç»´åº¦çš„é‡å ä½“ç´ æ•°

    try:
        gx = np.load(os.path.join(fpath, fname)).astype(np.float32).reshape(1, 1, *input_shape)
        print("âœ… Data loaded. Shape:", gx.shape)  # [1,1,D,H,W]
    except Exception as e:
        print(f"âŒ Error loading data: {e}")
        return

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device).eval()

    gx = torch.from_numpy(gx).to(device)  # [1,1,D,H,W]

    # è¾“å‡ºå¼ é‡ä¸æƒé‡å›¾ï¼ˆæŒ‰ç±»åˆ«æ•° 3ï¼‰
    B, C, D, H, W = gx.shape
    num_classes = 3
    output = torch.zeros((B, num_classes, D, H, W), device=device)
    weight_map = torch.zeros((B, 1, D, H, W), device=device)

    # é¢„è®¡ç®—å¹³æ»‘æƒé‡ (ä¸‰çº¿æ€§æ ¸)ï¼Œå¹¿æ’­åˆ° [B,1,d,h,w]
    weight = create_trilinear_weights(patch_d, overlap).to(device)  # [128,128,128]
    weight = weight.unsqueeze(0).unsqueeze(0)  # [1,1,128,128,128]

    # è®¡ç®—ä¸‰ä¸ªç»´åº¦çš„èµ·ç‚¹ç´¢å¼•
    d_starts = get_start_indices(D, patch_d, overlap)
    h_starts = get_start_indices(H, patch_h, overlap)
    w_starts = get_start_indices(W, patch_w, overlap)

    start = time.time()
    print("ğŸš€ Running 3D sliding-window prediction with trilinear smoothing...")
    print(f"   D starts: {d_starts}")
    print(f"   H starts: {h_starts}")
    print(f"   W starts: {w_starts}")

    try:
        with torch.no_grad():
            for ds in d_starts:
                de = ds + patch_d
                for hs in h_starts:
                    he = hs + patch_h
                    for ws in w_starts:
                        we = ws + patch_w

                        # å– 3D patch: [B, C, 128,128,128]
                        patch = gx[:, :, ds:de, hs:he, ws:we]

                        # æ¨¡å‹å‰å‘: æœŸæœ›è¾“å‡º [B, num_classes, 128,128,128]
                        pred_patch = model(patch)

                        # è‹¥æ¨¡å‹è¿”å› logitsï¼ˆä¸€èˆ¬å¦‚æ­¤ï¼‰ï¼Œç›´æ¥åŠ æƒèåˆï¼›éœ€è¦ softmax è¯·åœ¨è¿™é‡ŒåŠ 
                        # pred_patch = torch.softmax(pred_patch, dim=1)

                        # ä¸‰çº¿æ€§æƒé‡å¹³æ»‘
                        pred_patch = pred_patch * weight

                        # ç´¯åŠ é¢„æµ‹ä¸æƒé‡
                        output[:, :, ds:de, hs:he, ws:we] += pred_patch
                        weight_map[:, :, ds:de, hs:he, ws:we] += weight

        # é¿å…é™¤é›¶ï¼ˆé€šå¸¸ä¸ä¼šä¸ºé›¶ï¼‰
        weight_map = torch.clamp(weight_map, min=1e-6)
        output /= weight_map  # å¹¿æ’­åˆ°ç±»åˆ«ç»´

        # å–ç±»åˆ«æ ‡ç­¾
        preds = torch.argmax(output, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)

        print("âœ… Prediction completed in {:.2f}s.".format(time.time() - start))
        print("Prediction shape:", preds.shape)  # (D,H,W)

        # ä¿å­˜
        os.makedirs(output_dir, exist_ok=True)
        # np.save(os.path.join(output_dir, "94ChannelTUMSAApredicted_mask.npy"), preds)
        # np.save(os.path.join(output_dir, "94SHUNBEISeismicTUMSAApredicted_mask.npy"), preds)
        np.save(os.path.join(output_dir, "82SeismicTUMSAApredicted_mask82.npy"), preds)

        # å•ç‹¬ä¿å­˜ river / cave
        river_mask = (preds == 1).astype(np.uint8)
        cave_mask = (preds == 2).astype(np.uint8)
        # np.save(os.path.join(output_dir, "94ChannelTUMSAAriver_mask.npy"), river_mask)
        # np.save(os.path.join(output_dir, "94ChannelTUMSAAcave_mask.npy"), cave_mask)
        # np.save(os.path.join(output_dir, "94SHUNBEISeismicTUMSAAriver_mask.npy"), river_mask)
        # np.save(os.path.join(output_dir, "94SHUNBEISeismicTUMSAAcave_mask.npy"), cave_mask)
        np.save(os.path.join(output_dir, "82SeismicTUMSAAriver_mask82.npy"), river_mask)
        np.save(os.path.join(output_dir, "82SeismicTUMSAAcave_mask82.npy"), cave_mask)
        print("âœ… Saved river and cave masks.")

    except Exception as e:
        print(f"âŒ Error during prediction: {e}")


if __name__ == '__main__':
    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    config = configs.get_r50_b16_config()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = VisionTransformer(config, img_size=128, num_classes=21843, zero_head=False, vis=False).to(device)
    # 1. åŠ è½½æ¨¡å‹
    checkpoint = torch.load('/root/autodl-tmp/modelseismicTU-MSAA/SeismiccheckpointTUMSAA.91.pth')
    model.load_state_dict(checkpoint['state_dict'])  # ä½¿ç”¨ 'state_dict' é”®
    model.eval()
        
    seisPath = "/root/autodl-fs/ChannelKarst/seismic/"
    lxpath = "/root/autodl-fs/ChannelKarst/label/"
    predPath = "/root/autodl-fs/ChannelKarst/px/"
    # å®šä¹‰è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    ks = [140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 
          150, 151, 152, 153, 154, 155, 156, 157, 158, 159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190]
    
    for k in ks:
        fname = str(k)
        print(f"ğŸš€ Processing file: {fname}")
        goFakeValidation(model, fname, predPath)
        print(f"âœ… Finished processing {fname}")
        
#     # 2. è¿è¡Œé¢„æµ‹
#     result_files = goJie(
#         model=model,
#         fname="rwp384-896-128.npy",  # æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®æ–‡ä»¶å
#         # fname="SHB4_NORTH_slice640-512-128.npy",  # æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®æ–‡ä»¶å
#         # fname="Parihaka_sliceNew-ZHAO.npy",  # æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®æ–‡ä»¶å
#         # fname="seismic_192-slice4.npy",  # æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®æ–‡ä»¶å
#         # fname="Channel_128_512_512.npy",  # æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®æ–‡ä»¶å

#         output_dir="/root/autodl-fs/results/"  # æ›¿æ¢ä¸ºæ‚¨å¸Œæœ›ä¿å­˜è¾“å‡ºçš„ç›®å½•
#     )


# ######è¾“å‡ºç»“æœä¸ºlogit
# import torch
# import numpy as np
# import os
# import time

# # ä¸‰çº¿æ€§æ’å€¼å¹³æ»‘æƒé‡
# def create_trilinear_weights(size, overlap):
#     weights = np.ones((size, size, size), dtype=np.float32)
#     for i in range(size):
#         for j in range(size):
#             for k in range(size):
#                 wi = 1.0
#                 wj = 1.0
#                 wk = 1.0
#                 if i < overlap:
#                     wi = (i + 1) / (overlap + 1)
#                 elif i >= size - overlap:
#                     wi = (size - i) / (overlap + 1)
#                 if j < overlap:
#                     wj = (j + 1) / (overlap + 1)
#                 elif j >= size - overlap:
#                     wj = (size - j) / (overlap + 1)
#                 if k < overlap:
#                     wk = (k + 1) / (overlap + 1)
#                 elif k >= size - overlap:
#                     wk = (size - k) / (overlap + 1)
#                 weights[i, j, k] = wi * wj * wk
#     return torch.from_numpy(weights)

# def get_start_indices(length, window, overlap):
#     """è¿”å›èµ·ç‚¹åˆ—è¡¨ï¼Œæ­¥é•¿ = window - overlapï¼›å¹¶ä¿è¯æœ€åä¸€ä¸ªå—è¦†ç›–åˆ°æœ«å°¾ã€‚"""
#     stride = max(1, window - overlap)
#     idxs = list(range(0, max(0, length - window + 1), stride))
#     if len(idxs) == 0 or idxs[-1] != length - window:
#         idxs.append(length - window)
#     return idxs

# def goJie(model, fname, output_dir):
#     # æ–‡ä»¶è·¯å¾„è®¾ç½®
#     fpath = r"/root/autodl-fs/"
#     n1, n2, n3 = 128, 896, 384  # è¾“å…¥æ•°æ®çš„å°ºå¯¸
#     input_size = 128
#     overlap = 4
    
#     # å¼€å§‹è®¡æ—¶
#     start_time = time.time()

#     # åŠ è½½åœ°éœ‡æ•°æ®
#     try:
#         gx = np.load(fpath + fname)
#         gx = np.reshape(gx, (1, 1, n1, n2, n3))  # è½¬æ¢ä¸ºPyTorchæ ¼å¼
#         gx_torch = torch.from_numpy(gx).float()  # è½¬æ¢ä¸ºPyTorchå¼ é‡
#         print("Data loaded successfully. Shape:", gx_torch.shape)
#     except Exception as e:
#         print(f"Error loading data: {str(e)}")
#         return

#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#     model.to(device).eval()

#     gx_torch = gx_torch.to(device)  # [1, 1, 384, 896, 128]

#     # è·å–å„ä¸ªç»´åº¦çš„èµ·å§‹ä½ç½®
#     d_starts = get_start_indices(gx_torch.shape[2], input_size, overlap)
#     h_starts = get_start_indices(gx_torch.shape[3], input_size, overlap)
#     w_starts = get_start_indices(gx_torch.shape[4], input_size, overlap)

#     # è¾“å‡ºå¼ é‡ä¸æƒé‡å›¾ï¼ˆæŒ‰ç±»åˆ«æ•° 3ï¼‰
#     B, C, D, H, W = gx_torch.shape
#     num_classes = 3
#     output = torch.zeros((B, num_classes, D, H, W), device=device)
#     weight_map = torch.zeros((B, 1, D, H, W), device=device)

#     # åˆ›å»ºå¹³æ»‘æƒé‡ (ä¸‰çº¿æ€§æ ¸)ï¼Œå¹¿æ’­åˆ° [B,1,d,h,w]
#     weight = create_trilinear_weights(input_size, overlap).to(device)  # [128,128,128]
#     weight = weight.unsqueeze(0).unsqueeze(0)  # [1,1,128,128,128]
#     # åˆå§‹åŒ– logits_river å’Œ logits_cave
#     logits_river = torch.zeros((B, 1, D, H, W), device=device)
#     logits_cave = torch.zeros((B, 1, D, H, W), device=device)
#     # å¼€å§‹åˆ†å—é¢„æµ‹
#     try:

#         with torch.no_grad():
#             for ds in d_starts:
#                 de = ds + input_size
#                 for hs in h_starts:
#                     he = hs + input_size
#                     for ws in w_starts:
#                         we = ws + input_size

#                         # å– 3D patch: [B, C, 128,128,128]
#                         patch = gx_torch[:, :, ds:de, hs:he, ws:we]

#                         # æ¨¡å‹å‰å‘: æœŸæœ›è¾“å‡º [B, num_classes, 128,128,128]
#                         pred_patch = model(patch)

#                         # ä¸‰çº¿æ€§æƒé‡å¹³æ»‘
#                         pred_patch = pred_patch * weight

#                         # ç´¯åŠ é¢„æµ‹ä¸æƒé‡
#                         output[:, :, ds:de, hs:he, ws:we] += pred_patch
#                         weight_map[:, :, ds:de, hs:he, ws:we] += weight

#                         # åªä¿å­˜æ²³é“ä¸æº¶æ´çš„ logits
#                         logits_river[:, :, ds:de, hs:he, ws:we] += pred_patch[0, 1, :, :, :]  # å–æ²³é“ç±»çš„ logits
#                         logits_cave[:, :, ds:de, hs:he, ws:we] += pred_patch[0, 2, :, :, :]  # å–æº¶æ´ç±»çš„ logits

#         # é¿å…é™¤é›¶ï¼ˆé€šå¸¸ä¸ä¼šä¸ºé›¶ï¼‰
#         weight_map = torch.clamp(weight_map, min=1e-6)
#         output /= weight_map  # å¹¿æ’­åˆ°ç±»åˆ«ç»´

#         # è·å–æ¯ä¸ªä½“ç´ çš„ç±»åˆ«ï¼Œè¾“å‡ºå½¢çŠ¶ï¼š[1, 384, 896, 128]
#         preds = torch.argmax(output, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)

#         print("âœ… Prediction completed in {:.2f}s.".format(time.time() - start_time))
#         print("Prediction shape:", preds.shape)  # (D,H,W)
#         print(f"Channel: {logits_river.shape}")
#         print(f"Cave: {logits_cave.shape}")
        
#         # ä¿å­˜
#         os.makedirs(output_dir, exist_ok=True)

#         # å»æ‰æ‰€æœ‰å¤šä½™çš„ç»´åº¦ï¼Œå°† shape è½¬æ¢ä¸º (384, 896, 128)
#         logits_river = logits_river.squeeze().cpu().numpy()  # è¿™ä¼šå»æ‰æ‰€æœ‰ç»´åº¦ä¸º 1 çš„è½´
#         logits_cave = logits_cave.squeeze().cpu().numpy()  # åŒæ ·å»æ‰æ‰€æœ‰ç»´åº¦ä¸º 1 çš„è½´

#         print(f"Channel111: {logits_river.shape}")  # æœŸæœ›è¾“å‡º (384, 896, 128)
#         print(f"Cave111: {logits_cave.shape}")  # æœŸæœ›è¾“å‡º (384, 896, 128)


#         # ä¿å­˜æ²³é“æ¦‚ç‡
#         channel_file = os.path.join(output_dir, "Channel_prob.npy")
#         np.save(channel_file, logits_river)
#         print(f"Channel probability saved to {channel_file}")

#         # ä¿å­˜æº¶æ´æ¦‚ç‡
#         cave_file = os.path.join(output_dir, "Cave_prob.npy")
#         np.save(cave_file, logits_cave)
#         print(f"Cave probability saved to {cave_file}")
        
#         # å°†è¾“å‡ºå½¢çŠ¶è½¬ä¸º (D, H, W) (æ¯ä¸ªä½“ç´ çš„æœ€å¤§logitç±»åˆ«)
#         preds_final = np.moveaxis(preds, 0, -1)  # è½¬æ¢ä¸º (D, H, W) çš„å½¢çŠ¶

#         # ä¿å­˜æœ€ç»ˆåˆ†ç±»ç»“æœï¼ˆä¼˜å…ˆæº¶æ´ -> æ²³é“ -> èƒŒæ™¯ï¼‰
#         combined = np.zeros_like(preds_final, dtype=np.uint8)

#         # å…ˆæ ‡è®°æº¶æ´åŒºåŸŸä¸º 2
#         combined[preds_final == 2] = 2    # æº¶æ´ (æ¦‚ç‡>0.5)

#         # ç„¶åæ ‡è®°æ²³é“åŒºåŸŸä¸º 1ï¼Œåªæœ‰å½“æº¶æ´åŒºåŸŸä¸º 0 æ—¶æ‰æ ‡è®°
#         combined[(preds_final == 1) & (combined == 0)] = 1 # æ²³é“ (æ¦‚ç‡>0.5)

#         # ä¿å­˜æœ€ç»ˆçš„åˆ†ç±»ç»“æœ
#         combined_file = os.path.join(output_dir, "Combined_classification.npy")
#         np.save(combined_file, combined)
#         print(f"Combined classification saved to {combined_file}")

#     except Exception as e:
#         print(f"Error during prediction: {str(e)}")
#         return

# if __name__ == '__main__':
#     # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
#     config = configs.get_r50_b16_config()
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#     model = VisionTransformer(config, img_size=128, num_classes=21843, zero_head=False, vis=False).to(device)
    
#     # 1. åŠ è½½æ¨¡å‹
#     checkpoint = torch.load('/root/autodl-tmp/modelseismicTU-MSAA/SeismiccheckpointTUMSAA.94.pth')
#     model.load_state_dict(checkpoint['state_dict'])  # ä½¿ç”¨ 'state_dict' é”®
#     model.eval()

#     # 2. è¿è¡Œé¢„æµ‹
#     result_files = goJie(
#         model=model,
#         fname="rwp384-896-128.npy",  # æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®æ–‡ä»¶å
#         output_dir="/root/autodl-fs/results/"  # æ›¿æ¢ä¸ºæ‚¨å¸Œæœ›ä¿å­˜è¾“å‡ºçš„ç›®å½•
#     )
